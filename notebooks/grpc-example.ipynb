{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.io.decode_image(open('../images/sample.jpg', 'rb').read(), channels=3)\n",
    "img = tf.image.resize(img, [224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = tf.expand_dims(img, 0)\n",
    "image_tensor = image_tensor.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_CHARACTERS = {\n",
    "    0: \"abraham_grampa_simpson\", 1: \"apu_nahasapeemapetilon\", 2: \"barney_gumble\", 3: \"bart_simpson\",\n",
    "    4: \"carl_carlson\", 5: \"charles_montgomery_burns\", 6: \"chief_wiggum\", 7: \"comic_book_guy\",\n",
    "    8: \"disco_stu\", 9: \"edna_krabappel\", 10: \"groundskeeper_willie\", 11: \"homer_simpson\",\n",
    "    12: \"kent_brockman\", 13: \"krusty_the_clown\", 14: \"lenny_leonard\", 15: \"lisa_simpson\",\n",
    "    16: \"maggie_simpson\", 17: \"marge_simpson\", 18: \"martin_prince\", 19: \"mayor_quimby\",\n",
    "    20: \"milhouse_van_houten\", 21: \"moe_szyslak\", 22: \"ned_flanders\", 23: \"nelson_muntz\",\n",
    "    24: \"patty_bouvier\", 25: \"principal_skinner\", 26: \"professor_john_frink\", 27: \"ralph_wiggum\",\n",
    "    28: \"selma_bouvier\", 29: \"sideshow_bob\", 30: \"snake_jailbird\", 31: \"waylon_smithers\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer_simpson\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2, prediction_service_pb2_grpc\n",
    "\n",
    "# Optional: Define the proper message lenght in bytes\n",
    "MAX_MESSAGE_LENGTH = 20000000\n",
    "\n",
    "REQUEST_TIMEOUT = 10\n",
    "\n",
    "# Open a gRPC insecure channel\n",
    "channel = grpc.insecure_channel(\n",
    "    \"localhost:8500\",\n",
    "    options=[\n",
    "        (\"grpc.max_send_message_length\", MAX_MESSAGE_LENGTH),\n",
    "        (\"grpc.max_receive_message_length\", MAX_MESSAGE_LENGTH),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create the PredictionServiceStub\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "# Create the PredictRequest and set its values\n",
    "req = predict_pb2.PredictRequest()\n",
    "req.model_spec.name = 'simpsonsnet'\n",
    "req.model_spec.signature_name = ''\n",
    "\n",
    "# Convert to Tensor Proto and send the request\n",
    "# Note that shape is in NHWC (num_samples x height x width x channels) format\n",
    "tensor = tf.make_tensor_proto(image_tensor)\n",
    "req.inputs[\"conv2d_input\"].CopyFrom(tensor)  # Available at /metadata\n",
    "\n",
    "# Send request\n",
    "response = stub.Predict(req, REQUEST_TIMEOUT)\n",
    "\n",
    "# Handle request's output\n",
    "output_tensor_proto = response.outputs[\"dense_2\"]  # Available at /metadata\n",
    "shape = tf.TensorShape(output_tensor_proto.tensor_shape)\n",
    "\n",
    "result = tf.reshape(output_tensor_proto.float_val, shape)\n",
    "result = tf.argmax(result, 1).numpy()[0]\n",
    "print(MAP_CHARACTERS[result])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
